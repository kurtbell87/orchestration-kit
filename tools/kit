#!/usr/bin/env python3
"""Master-kit orchestrator entrypoint.

Usage:
  tools/kit <kit> <phase> [args...]
  tools/kit request [options]
"""

from __future__ import annotations

import argparse
import datetime as dt
import glob
import fcntl
import hashlib
import json
import os
import re
import socket
import subprocess
import sys
import uuid
from pathlib import Path
from typing import Any

REPO_ROOT = Path(__file__).resolve().parent.parent
PROJECT_ROOT = Path(os.environ["PROJECT_ROOT"]) if os.environ.get("PROJECT_ROOT") else None
RUNS_DIR = REPO_ROOT / "runs"
INTEROP_REQUESTS_DIR = REPO_ROOT / "interop" / "requests"
DASHBOARD_TOOL = REPO_ROOT / "tools" / "dashboard"

KIT_CONFIG: dict[str, dict[str, Any]] = {
    "tdd": {
        "cwd": REPO_ROOT / "claude-tdd-kit",
        "script": "./tdd.sh",
        "truth_patterns": [
            "PRD.md",
            "LAST_TOUCH.md",
            "docs/**",
            "tests/**",
        ],
        "tracked_globs": [
            "docs/**",
            "src/**",
            "tests/**",
            "PRD.md",
            "LAST_TOUCH.md",
        ],
    },
    "research": {
        "cwd": REPO_ROOT / "claude-research-kit",
        "script": "./experiment.sh",
        "truth_patterns": [
            "QUESTIONS.md",
            "experiments/**",
            "results/**/metrics.*",
            "analysis.md",
            "SYNTHESIS.md",
            "RESEARCH_LOG.md",
        ],
        "tracked_globs": [
            "experiments/**",
            "results/**",
            "analysis.md",
            "SYNTHESIS.md",
            "RESEARCH_LOG.md",
            "handoffs/**",
        ],
    },
    "math": {
        "cwd": REPO_ROOT / "claude-mathematics-kit",
        "script": "./math.sh",
        "truth_patterns": [
            "specs/**",
            "CONSTRUCTIONS.md",
            "CONSTRUCTION_LOG.md",
            "REVISION.md",
            "results/**",
        ],
        "tracked_globs": [
            "specs/**",
            "**/*.lean",
            "CONSTRUCTION_LOG.md",
            "REVISION.md",
            "CONSTRUCTIONS.md",
            "results/**",
        ],
    },
}

CAPSULE_START = "===CAPSULE==="
CAPSULE_END = "===/CAPSULE==="


def now_iso() -> str:
    return dt.datetime.now(dt.timezone.utc).isoformat(timespec="seconds").replace("+00:00", "Z")


def make_run_id() -> str:
    ts = dt.datetime.now(dt.timezone.utc).strftime("%Y%m%dT%H%M%SZ")
    return f"{ts}-{uuid.uuid4().hex[:8]}"


def int_env(name: str, default: int) -> int:
    raw = os.getenv(name)
    if raw is None:
        return default
    try:
        return int(raw)
    except ValueError:
        return default


def env_enabled(name: str, default: bool = True) -> bool:
    raw = os.getenv(name)
    if raw is None:
        return default
    return raw.strip().lower() not in {"0", "false", "no", "off"}


def parse_project_id(stdout: str) -> str | None:
    lines = [ln.strip() for ln in stdout.splitlines() if ln.strip()]
    for line in reversed(lines):
        try:
            payload = json.loads(line)
        except json.JSONDecodeError:
            continue
        if not isinstance(payload, dict):
            continue
        project_id = payload.get("project_id")
        if isinstance(project_id, str) and project_id:
            return project_id
    return None


def dashboard_manage_project(project_root: Path) -> str | None:
    if not env_enabled("MASTER_KIT_DASHBOARD_AUTOSTART", default=True):
        return None
    if not DASHBOARD_TOOL.is_file():
        return None

    label = os.getenv("MASTER_KIT_DASHBOARD_LABEL", project_root.name)
    register = subprocess.run(
        [
            str(DASHBOARD_TOOL),
            "register",
            "--master-kit-root",
            str(REPO_ROOT),
            "--project-root",
            str(project_root),
            "--label",
            label,
        ],
        cwd=str(REPO_ROOT),
        env=os.environ.copy(),
        text=True,
        capture_output=True,
        check=False,
    )
    project_id = parse_project_id(register.stdout)
    if register.returncode != 0:
        print(
            f"[tools/kit] dashboard register failed (continuing): {register.stderr.strip() or register.stdout.strip()}",
            file=sys.stderr,
        )
        return project_id

    ensure = subprocess.run(
        [
            str(DASHBOARD_TOOL),
            "ensure-service",
            "--wait-seconds",
            os.getenv("MASTER_KIT_DASHBOARD_ENSURE_WAIT_SECONDS", "1"),
        ],
        cwd=str(REPO_ROOT),
        env=os.environ.copy(),
        text=True,
        capture_output=True,
        check=False,
    )
    if ensure.returncode != 0:
        print(
            f"[tools/kit] dashboard ensure-service failed (continuing): {ensure.stderr.strip() or ensure.stdout.strip()}",
            file=sys.stderr,
        )

    return project_id


def dashboard_index_project(project_id: str | None) -> None:
    if not env_enabled("MASTER_KIT_DASHBOARD_AUTO_INDEX", default=True):
        return
    if not DASHBOARD_TOOL.is_file():
        return
    if not isinstance(project_id, str) or not project_id:
        return

    proc = subprocess.run(
        [str(DASHBOARD_TOOL), "index", "--project-id", project_id],
        cwd=str(REPO_ROOT),
        env=os.environ.copy(),
        text=True,
        capture_output=True,
        check=False,
    )
    if proc.returncode != 0:
        print(
            f"[tools/kit] dashboard index failed (continuing): {proc.stderr.strip() or proc.stdout.strip()}",
            file=sys.stderr,
        )


def run_project_root() -> Path:
    if PROJECT_ROOT is not None:
        return PROJECT_ROOT.resolve()
    return REPO_ROOT.resolve()


def runtime_identity() -> str:
    raw = os.getenv("MASTER_KIT_AGENT_RUNTIME", "").strip()
    if raw:
        return raw

    if os.getenv("CLAUDE_CODE"):
        return "claude"
    if os.getenv("CODEX_ENV"):
        return "codex"
    return "direct"


def rel_repo(path: Path) -> str:
    if PROJECT_ROOT is not None:
        try:
            return str(path.relative_to(PROJECT_ROOT))
        except ValueError:
            pass
    try:
        return str(path.relative_to(REPO_ROOT))
    except ValueError:
        return str(path)


def ensure_run_dirs(run_root: Path) -> None:
    for part in ("capsules", "manifests", "logs", "artifacts"):
        (run_root / part).mkdir(parents=True, exist_ok=True)


def append_event(events_path: Path, event: str, **payload: Any) -> None:
    record = {"ts": now_iso(), "event": event}
    record.update(payload)
    with events_path.open("a", encoding="utf-8") as fh:
        fcntl.flock(fh, fcntl.LOCK_EX)
        try:
            json.dump(record, fh, sort_keys=True)
            fh.write("\n")
            fh.flush()
        finally:
            fcntl.flock(fh, fcntl.LOCK_UN)


def expand_file_patterns(base_dir: Path, patterns: list[str], limit: int = 400) -> list[Path]:
    found: set[Path] = set()
    for pattern in patterns:
        query = str(base_dir / pattern)
        for matched in glob.glob(query, recursive=True):
            candidate = Path(matched)
            if candidate.is_file():
                found.add(candidate.resolve())
    ordered = sorted(found)
    if len(ordered) > limit:
        return ordered[:limit]
    return ordered


def sha256_file(path: Path) -> str:
    digest = hashlib.sha256()
    with path.open("rb") as fh:
        for block in iter(lambda: fh.read(1024 * 1024), b""):
            digest.update(block)
    return digest.hexdigest()


def classify_kind(path: Path) -> str:
    suffix = path.suffix.lower()
    if suffix in {".md", ".markdown"}:
        return "markdown"
    if suffix == ".json":
        return "json"
    if suffix in {".yaml", ".yml"}:
        return "yaml"
    if suffix in {".py", ".sh", ".ts", ".js", ".rs", ".c", ".cpp", ".hpp", ".h"}:
        return "source"
    if suffix == ".lean":
        return "lean"
    if suffix in {".txt", ".log"}:
        return "text"
    return "file"


def build_artifact_index(
    files: list[Path],
    *,
    max_files: int,
    max_total_bytes: int,
) -> tuple[list[dict[str, Any]], dict[str, int]]:
    tracked: list[dict[str, Any]] = []
    total_bytes = 0
    omitted_files = 0
    omitted_bytes = 0

    for path in files:
        size = path.stat().st_size
        if len(tracked) >= max_files or (total_bytes + size) > max_total_bytes:
            omitted_files += 1
            omitted_bytes += size
            continue

        tracked.append(
            {
                "path": rel_repo(path),
                "kind": classify_kind(path),
                "bytes": size,
                "sha256": sha256_file(path),
            }
        )
        total_bytes += size

    return tracked, {
        "files": omitted_files,
        "bytes": omitted_bytes,
    }


def extract_capsule_text(log_path: Path) -> list[str]:
    text = log_path.read_text(encoding="utf-8", errors="replace")
    pattern = re.compile(
        re.escape(CAPSULE_START) + r"\s*(.*?)\s*" + re.escape(CAPSULE_END),
        flags=re.DOTALL,
    )
    matches = pattern.findall(text)
    if not matches:
        return []

    raw = matches[-1]
    lines = [ln.rstrip() for ln in raw.splitlines()]
    lines = [ln for ln in lines if ln.strip() and "```" not in ln]
    return lines[:30]


def fallback_capsule(
    *,
    kit: str,
    phase: str,
    run_id: str,
    exit_code: int,
    log_path: Path,
    manifest_path: Path,
) -> list[str]:
    status = "ok" if exit_code == 0 else "failed"
    lines = [
        f"Goal: Execute {kit}.{phase} in master-kit orchestration.",
        f"What happened: Command finished with exit code {exit_code}.",
        f"Current status: {status}.",
    ]
    # On failure, include the last lines of the log so the capsule is
    # actionable without requiring a separate log read.
    if exit_code != 0 and log_path.exists():
        try:
            raw = log_path.read_text(encoding="utf-8", errors="replace")
            # Strip ANSI escape codes for readability.
            raw = re.sub(r"\x1b\[[0-9;]*m", "", raw)
            tail = [ln.rstrip() for ln in raw.splitlines() if ln.strip()]
            tail = tail[-15:]  # last 15 non-blank lines
            if tail:
                lines.append("Error output (last lines of log):")
                lines.extend(f"  {ln}" for ln in tail)
        except OSError:
            pass
    if exit_code == 0:
        next_action = "Next action requested (exactly one): proceed to next phase."
        blocked = "If blocked: n/a"
    else:
        next_action = "Next action requested (exactly one): read this capsule and decide whether to retry or stop."
        blocked = "If blocked: check error output above; fix the root cause before retrying."
    lines.extend([
        next_action,
        "Evidence pointers:",
        f"- log: {rel_repo(log_path)}",
        f"- manifest: {rel_repo(manifest_path)}",
        blocked,
        f"Run: {run_id}",
    ])
    return lines


def write_capsule(
    *,
    capsule_path: Path,
    kit: str,
    phase: str,
    run_id: str,
    exit_code: int,
    log_path: Path,
    manifest_path: Path,
) -> None:
    lines = extract_capsule_text(log_path)
    if not lines:
        lines = fallback_capsule(
            kit=kit,
            phase=phase,
            run_id=run_id,
            exit_code=exit_code,
            log_path=log_path,
            manifest_path=manifest_path,
        )
    if len(lines) > 30:
        lines = lines[:30]

    capsule_path.parent.mkdir(parents=True, exist_ok=True)
    capsule_path.write_text("\n".join(lines).strip() + "\n", encoding="utf-8")


def run_phase(argv: list[str]) -> int:
    parser = argparse.ArgumentParser(prog="tools/kit", add_help=True)
    parser.add_argument("kit", choices=sorted(KIT_CONFIG.keys()))
    parser.add_argument("phase")
    parser.add_argument("phase_args", nargs=argparse.REMAINDER)
    parser.add_argument("--json", action="store_true", dest="json_out")
    parser.add_argument("--reasoning", default=None, help="1-3 sentence justification for this dispatch")
    parser.add_argument("--run-id", default=None)
    parser.add_argument("--parent-run-id", default=os.getenv("RUN_ID"))
    parser.add_argument(
        "--tracked-max-files",
        type=int,
        default=int(os.getenv("MAX_TRACKED_FILES", "400")),
    )
    parser.add_argument(
        "--tracked-max-bytes",
        type=int,
        default=int(os.getenv("MAX_TRACKED_BYTES", "20000000")),
    )

    args = parser.parse_args(argv)

    config = KIT_CONFIG[args.kit]
    cwd: Path = PROJECT_ROOT if PROJECT_ROOT is not None else config["cwd"]
    script: str = config["script"]
    project_root = run_project_root()
    dashboard_project_id = dashboard_manage_project(project_root)
    master_kit_root = REPO_ROOT.resolve()
    run_context = {
        "project_root": str(project_root),
        "master_kit_root": str(master_kit_root),
        "agent_runtime": runtime_identity(),
        "host": socket.gethostname(),
        "pid": os.getpid(),
    }

    run_id = args.run_id or make_run_id()
    run_root = RUNS_DIR / run_id
    ensure_run_dirs(run_root)

    events_path = run_root / "events.jsonl"
    capsule_path = run_root / "capsules" / f"{args.kit}_{args.phase}.md"
    manifest_path = run_root / "manifests" / f"{args.kit}_{args.phase}.json"
    log_path = run_root / "logs" / f"{args.kit}_{args.phase}.log"

    started_at = now_iso()

    append_event(
        events_path,
        "run_started",
        run_id=run_id,
        parent_run_id=args.parent_run_id,
        kit=args.kit,
        phase=args.phase,
        reasoning=args.reasoning,
        **run_context,
    )
    append_event(
        events_path,
        "phase_started",
        run_id=run_id,
        kit=args.kit,
        phase=args.phase,
        command=[script, args.phase] + args.phase_args,
        cwd=str(cwd.resolve()),
    )

    cmd = [script, args.phase] + args.phase_args
    env = os.environ.copy()
    env.update(
        {
            "RUN_ID": run_id,
            "RUN_ROOT": str(run_root),
            "MASTER_KIT_ROOT": str(REPO_ROOT),
            "READ_BUDGET_STATE_DIR": str(run_root / "artifacts"),
        }
    )
    if PROJECT_ROOT is not None:
        env["PROJECT_ROOT"] = str(PROJECT_ROOT)
    if args.parent_run_id:
        env["PARENT_RUN_ID"] = args.parent_run_id

    with log_path.open("wb") as log_fh:
        proc = subprocess.run(
            cmd,
            cwd=str(cwd),
            env=env,
            stdout=log_fh,
            stderr=subprocess.STDOUT,
            check=False,
        )

    finished_at = now_iso()
    exit_code = proc.returncode

    append_event(
        events_path,
        "phase_finished",
        run_id=run_id,
        kit=args.kit,
        phase=args.phase,
        exit_code=exit_code,
        log_path=rel_repo(log_path),
        **run_context,
    )

    tracked_files = expand_file_patterns(cwd, config["tracked_globs"])
    tracked, omitted = build_artifact_index(
        tracked_files,
        max_files=max(args.tracked_max_files, 1),
        max_total_bytes=max(args.tracked_max_bytes, 1),
    )
    append_event(
        events_path,
        "artifact_indexed",
        run_id=run_id,
        kit=args.kit,
        phase=args.phase,
        tracked_count=len(tracked),
        omitted_files=omitted["files"],
        omitted_bytes=omitted["bytes"],
    )

    truth_paths = [rel_repo(path) for path in expand_file_patterns(cwd, config["truth_patterns"], limit=120)]

    write_capsule(
        capsule_path=capsule_path,
        kit=args.kit,
        phase=args.phase,
        run_id=run_id,
        exit_code=exit_code,
        log_path=log_path,
        manifest_path=manifest_path,
    )

    append_event(
        events_path,
        "capsule_written",
        run_id=run_id,
        kit=args.kit,
        phase=args.phase,
        capsule_path=rel_repo(capsule_path),
    )

    manifest = {
        "metadata": {
            "run_id": run_id,
            "parent_run_id": args.parent_run_id,
            "kit": args.kit,
            "phase": args.phase,
            "started_at": started_at,
            "finished_at": finished_at,
            "exit_code": exit_code,
            "command": cmd,
            "cwd": rel_repo(cwd),
            "project_root": str(project_root),
            "master_kit_root": str(master_kit_root),
            "agent_runtime": run_context["agent_runtime"],
            "host": run_context["host"],
            "pid": run_context["pid"],
            "reasoning": args.reasoning,
            "read_budget": {
                "max_files": int_env("READ_BUDGET_MAX_FILES", 0),
                "max_total_bytes": int_env("READ_BUDGET_MAX_TOTAL_BYTES", 0),
                "max_read_bytes": int_env("MAX_READ_BYTES", 200000),
            },
        },
        "artifact_index": {
            "tracked": tracked,
            "omitted": omitted,
            "limits": {
                "max_files": args.tracked_max_files,
                "max_total_bytes": args.tracked_max_bytes,
            },
        },
        "truth_pointers": truth_paths,
        "log_pointers": [
            {
                "path": rel_repo(log_path),
                "kind": "phase_log",
                "hint": f"tail -n 200 {rel_repo(log_path)}",
            }
        ],
        "capsule_path": rel_repo(capsule_path),
    }

    manifest_path.write_text(json.dumps(manifest, indent=2, sort_keys=True) + "\n", encoding="utf-8")

    append_event(
        events_path,
        "manifest_written",
        run_id=run_id,
        kit=args.kit,
        phase=args.phase,
        manifest_path=rel_repo(manifest_path),
        **run_context,
    )
    append_event(
        events_path,
        "run_finished",
        run_id=run_id,
        kit=args.kit,
        phase=args.phase,
        exit_code=exit_code,
        capsule_path=rel_repo(capsule_path),
        manifest_path=rel_repo(manifest_path),
        **run_context,
    )

    output = {
        "run_id": run_id,
        "status": "ok" if exit_code == 0 else "failed",
        "exit_code": exit_code,
        "kit": args.kit,
        "phase": args.phase,
        "reasoning": args.reasoning,
        "paths": {
            "run_root": rel_repo(run_root),
            "events": rel_repo(events_path),
            "log": rel_repo(log_path),
            "capsule": rel_repo(capsule_path),
            "manifest": rel_repo(manifest_path),
        },
    }

    if args.json_out:
        print(json.dumps(output, sort_keys=True))
    else:
        print(f"run_id={run_id}")
        print(f"status={output['status']}")
        print(f"exit_code={exit_code}")
        print(f"events={output['paths']['events']}")
        print(f"capsule={output['paths']['capsule']}")
        print(f"manifest={output['paths']['manifest']}")
        print(f"log={output['paths']['log']}")

    dashboard_index_project(dashboard_project_id)

    return 0 if exit_code == 0 else exit_code


def make_request(argv: list[str]) -> int:
    parser = argparse.ArgumentParser(prog="tools/kit request", add_help=True)
    parser.add_argument("--request-id", default=None)
    parser.add_argument("--from", dest="from_kit", required=True, choices=sorted(KIT_CONFIG.keys()))
    parser.add_argument("--from-phase", dest="from_phase", default=None)
    parser.add_argument("--to", dest="to_kit", required=True, choices=sorted(KIT_CONFIG.keys()))
    parser.add_argument("--action", required=True)
    parser.add_argument("--run-id", required=True)
    parser.add_argument("--arg", dest="args", action="append", default=[])
    parser.add_argument("--input", dest="inputs", action="append", default=[])
    parser.add_argument("--must-read", dest="must_read", action="append", default=[])
    parser.add_argument("--allowed-path", dest="allowed_paths", action="append", default=[])
    parser.add_argument("--deliverable", dest="deliverables", action="append", default=[])
    parser.add_argument("--max-files", type=int, default=8)
    parser.add_argument("--max-total-bytes", type=int, default=300_000)
    parser.add_argument("--priority", default="normal")
    parser.add_argument("--reasoning", default=None, help="1-3 sentence justification for this request")
    parser.add_argument("--json", action="store_true", dest="json_out")

    args = parser.parse_args(argv)

    dashboard_project_id = dashboard_manage_project(run_project_root())

    request_id = args.request_id or f"rq-{dt.datetime.now(dt.timezone.utc).strftime('%Y%m%dT%H%M%SZ')}-{uuid.uuid4().hex[:6]}"
    payload = {
        "request_id": request_id,
        "from_kit": args.from_kit,
        "from_phase": args.from_phase,
        "to_kit": args.to_kit,
        "action": args.action,
        "args": args.args,
        "run_id": args.run_id,
        "inputs": args.inputs,
        "must_read": args.must_read,
        "read_budget": {
            "max_files": args.max_files,
            "max_total_bytes": args.max_total_bytes,
            "allowed_paths": args.allowed_paths,
        },
        "deliverables_expected": args.deliverables,
        "priority": args.priority,
        "reasoning": args.reasoning,
    }

    INTEROP_REQUESTS_DIR.mkdir(parents=True, exist_ok=True)
    request_path = INTEROP_REQUESTS_DIR / f"{request_id}.json"
    request_path.write_text(json.dumps(payload, indent=2, sort_keys=True) + "\n", encoding="utf-8")

    output = {
        "request_id": request_id,
        "path": rel_repo(request_path),
        "reasoning": args.reasoning,
    }
    if args.json_out:
        print(json.dumps(output, sort_keys=True))
    else:
        print(f"request_id={request_id}")
        print(f"path={rel_repo(request_path)}")

    dashboard_index_project(dashboard_project_id)

    return 0


def main(argv: list[str]) -> int:
    if not argv:
        print("Usage: tools/kit <kit> <phase> [args...] | tools/kit request [options]", file=sys.stderr)
        return 2

    if argv[0] == "request":
        return make_request(argv[1:])

    return run_phase(argv)


if __name__ == "__main__":
    raise SystemExit(main(sys.argv[1:]))
