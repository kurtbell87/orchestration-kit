#!/usr/bin/env python3
"""Master-kit orchestrator entrypoint.

Usage:
  tools/kit <kit> <phase> [args...]
  tools/kit request [options]
"""

from __future__ import annotations

import argparse
import datetime as dt
import glob
import hashlib
import json
import os
import re
import subprocess
import sys
import uuid
from pathlib import Path
from typing import Any

REPO_ROOT = Path(__file__).resolve().parent.parent
PROJECT_ROOT = Path(os.environ["PROJECT_ROOT"]) if os.environ.get("PROJECT_ROOT") else None
RUNS_DIR = REPO_ROOT / "runs"
INTEROP_REQUESTS_DIR = REPO_ROOT / "interop" / "requests"

KIT_CONFIG: dict[str, dict[str, Any]] = {
    "tdd": {
        "cwd": REPO_ROOT / "claude-tdd-kit",
        "script": "./tdd.sh",
        "truth_patterns": [
            "PRD.md",
            "LAST_TOUCH.md",
            "docs/**",
            "tests/**",
        ],
        "tracked_globs": [
            "docs/**",
            "src/**",
            "tests/**",
            "PRD.md",
            "LAST_TOUCH.md",
        ],
    },
    "research": {
        "cwd": REPO_ROOT / "claude-research-kit",
        "script": "./experiment.sh",
        "truth_patterns": [
            "QUESTIONS.md",
            "experiments/**",
            "results/**/metrics.*",
            "analysis.md",
            "SYNTHESIS.md",
            "RESEARCH_LOG.md",
        ],
        "tracked_globs": [
            "experiments/**",
            "results/**",
            "analysis.md",
            "SYNTHESIS.md",
            "RESEARCH_LOG.md",
            "handoffs/**",
        ],
    },
    "math": {
        "cwd": REPO_ROOT / "claude-mathematics-kit",
        "script": "./math.sh",
        "truth_patterns": [
            "specs/**",
            "CONSTRUCTIONS.md",
            "CONSTRUCTION_LOG.md",
            "REVISION.md",
            "results/**",
        ],
        "tracked_globs": [
            "specs/**",
            "**/*.lean",
            "CONSTRUCTION_LOG.md",
            "REVISION.md",
            "CONSTRUCTIONS.md",
            "results/**",
        ],
    },
}

CAPSULE_START = "===CAPSULE==="
CAPSULE_END = "===/CAPSULE==="


def now_iso() -> str:
    return dt.datetime.now(dt.timezone.utc).isoformat(timespec="seconds").replace("+00:00", "Z")


def make_run_id() -> str:
    ts = dt.datetime.now(dt.timezone.utc).strftime("%Y%m%dT%H%M%SZ")
    return f"{ts}-{uuid.uuid4().hex[:8]}"


def int_env(name: str, default: int) -> int:
    raw = os.getenv(name)
    if raw is None:
        return default
    try:
        return int(raw)
    except ValueError:
        return default


def rel_repo(path: Path) -> str:
    if PROJECT_ROOT is not None:
        try:
            return str(path.relative_to(PROJECT_ROOT))
        except ValueError:
            pass
    try:
        return str(path.relative_to(REPO_ROOT))
    except ValueError:
        return str(path)


def ensure_run_dirs(run_root: Path) -> None:
    for part in ("capsules", "manifests", "logs", "artifacts"):
        (run_root / part).mkdir(parents=True, exist_ok=True)


def append_event(events_path: Path, event: str, **payload: Any) -> None:
    record = {"ts": now_iso(), "event": event}
    record.update(payload)
    with events_path.open("a", encoding="utf-8") as fh:
        json.dump(record, fh, sort_keys=True)
        fh.write("\n")


def expand_file_patterns(base_dir: Path, patterns: list[str], limit: int = 400) -> list[Path]:
    found: set[Path] = set()
    for pattern in patterns:
        query = str(base_dir / pattern)
        for matched in glob.glob(query, recursive=True):
            candidate = Path(matched)
            if candidate.is_file():
                found.add(candidate.resolve())
    ordered = sorted(found)
    if len(ordered) > limit:
        return ordered[:limit]
    return ordered


def sha256_file(path: Path) -> str:
    digest = hashlib.sha256()
    with path.open("rb") as fh:
        for block in iter(lambda: fh.read(1024 * 1024), b""):
            digest.update(block)
    return digest.hexdigest()


def classify_kind(path: Path) -> str:
    suffix = path.suffix.lower()
    if suffix in {".md", ".markdown"}:
        return "markdown"
    if suffix == ".json":
        return "json"
    if suffix in {".yaml", ".yml"}:
        return "yaml"
    if suffix in {".py", ".sh", ".ts", ".js", ".rs", ".c", ".cpp", ".hpp", ".h"}:
        return "source"
    if suffix == ".lean":
        return "lean"
    if suffix in {".txt", ".log"}:
        return "text"
    return "file"


def build_artifact_index(
    files: list[Path],
    *,
    max_files: int,
    max_total_bytes: int,
) -> tuple[list[dict[str, Any]], dict[str, int]]:
    tracked: list[dict[str, Any]] = []
    total_bytes = 0
    omitted_files = 0
    omitted_bytes = 0

    for path in files:
        size = path.stat().st_size
        if len(tracked) >= max_files or (total_bytes + size) > max_total_bytes:
            omitted_files += 1
            omitted_bytes += size
            continue

        tracked.append(
            {
                "path": rel_repo(path),
                "kind": classify_kind(path),
                "bytes": size,
                "sha256": sha256_file(path),
            }
        )
        total_bytes += size

    return tracked, {
        "files": omitted_files,
        "bytes": omitted_bytes,
    }


def extract_capsule_text(log_path: Path) -> list[str]:
    text = log_path.read_text(encoding="utf-8", errors="replace")
    pattern = re.compile(
        re.escape(CAPSULE_START) + r"\s*(.*?)\s*" + re.escape(CAPSULE_END),
        flags=re.DOTALL,
    )
    matches = pattern.findall(text)
    if not matches:
        return []

    raw = matches[-1]
    lines = [ln.rstrip() for ln in raw.splitlines()]
    lines = [ln for ln in lines if ln.strip() and "```" not in ln]
    return lines[:30]


def fallback_capsule(
    *,
    kit: str,
    phase: str,
    run_id: str,
    exit_code: int,
    log_path: Path,
    manifest_path: Path,
) -> list[str]:
    status = "ok" if exit_code == 0 else "failed"
    lines = [
        f"Goal: Execute {kit}.{phase} in master-kit orchestration.",
        f"What happened: Command finished with exit code {exit_code}.",
        f"Current status: {status}.",
    ]
    # On failure, include the last lines of the log so the capsule is
    # actionable without requiring a separate log read.
    if exit_code != 0 and log_path.exists():
        try:
            raw = log_path.read_text(encoding="utf-8", errors="replace")
            # Strip ANSI escape codes for readability.
            raw = re.sub(r"\x1b\[[0-9;]*m", "", raw)
            tail = [ln.rstrip() for ln in raw.splitlines() if ln.strip()]
            tail = tail[-15:]  # last 15 non-blank lines
            if tail:
                lines.append("Error output (last lines of log):")
                lines.extend(f"  {ln}" for ln in tail)
        except OSError:
            pass
    lines.extend([
        "Evidence pointers:",
        f"- log: {rel_repo(log_path)}",
        f"- manifest: {rel_repo(manifest_path)}",
        f"Run: {run_id}",
    ])
    return lines


def write_capsule(
    *,
    capsule_path: Path,
    kit: str,
    phase: str,
    run_id: str,
    exit_code: int,
    log_path: Path,
    manifest_path: Path,
) -> None:
    lines = extract_capsule_text(log_path)
    if not lines:
        lines = fallback_capsule(
            kit=kit,
            phase=phase,
            run_id=run_id,
            exit_code=exit_code,
            log_path=log_path,
            manifest_path=manifest_path,
        )
    if len(lines) > 30:
        lines = lines[:30]

    capsule_path.parent.mkdir(parents=True, exist_ok=True)
    capsule_path.write_text("\n".join(lines).strip() + "\n", encoding="utf-8")


def run_phase(argv: list[str]) -> int:
    parser = argparse.ArgumentParser(prog="tools/kit", add_help=True)
    parser.add_argument("kit", choices=sorted(KIT_CONFIG.keys()))
    parser.add_argument("phase")
    parser.add_argument("phase_args", nargs=argparse.REMAINDER)
    parser.add_argument("--json", action="store_true", dest="json_out")
    parser.add_argument("--run-id", default=None)
    parser.add_argument("--parent-run-id", default=os.getenv("RUN_ID"))
    parser.add_argument(
        "--tracked-max-files",
        type=int,
        default=int(os.getenv("MAX_TRACKED_FILES", "400")),
    )
    parser.add_argument(
        "--tracked-max-bytes",
        type=int,
        default=int(os.getenv("MAX_TRACKED_BYTES", "20000000")),
    )

    args = parser.parse_args(argv)

    config = KIT_CONFIG[args.kit]
    cwd: Path = PROJECT_ROOT if PROJECT_ROOT is not None else config["cwd"]
    script: str = config["script"]

    run_id = args.run_id or make_run_id()
    run_root = RUNS_DIR / run_id
    ensure_run_dirs(run_root)

    events_path = run_root / "events.jsonl"
    capsule_path = run_root / "capsules" / f"{args.kit}_{args.phase}.md"
    manifest_path = run_root / "manifests" / f"{args.kit}_{args.phase}.json"
    log_path = run_root / "logs" / f"{args.kit}_{args.phase}.log"

    started_at = now_iso()

    append_event(
        events_path,
        "run_started",
        run_id=run_id,
        parent_run_id=args.parent_run_id,
        kit=args.kit,
        phase=args.phase,
    )
    append_event(
        events_path,
        "phase_started",
        run_id=run_id,
        kit=args.kit,
        phase=args.phase,
        command=[script, args.phase] + args.phase_args,
    )

    cmd = [script, args.phase] + args.phase_args
    env = os.environ.copy()
    env.update(
        {
            "RUN_ID": run_id,
            "RUN_ROOT": str(run_root),
            "MASTER_KIT_ROOT": str(REPO_ROOT),
            "READ_BUDGET_STATE_DIR": str(run_root / "artifacts"),
        }
    )
    if PROJECT_ROOT is not None:
        env["PROJECT_ROOT"] = str(PROJECT_ROOT)
    if args.parent_run_id:
        env["PARENT_RUN_ID"] = args.parent_run_id

    with log_path.open("wb") as log_fh:
        proc = subprocess.run(
            cmd,
            cwd=str(cwd),
            env=env,
            stdout=log_fh,
            stderr=subprocess.STDOUT,
            check=False,
        )

    finished_at = now_iso()
    exit_code = proc.returncode

    append_event(
        events_path,
        "phase_finished",
        run_id=run_id,
        kit=args.kit,
        phase=args.phase,
        exit_code=exit_code,
        log_path=rel_repo(log_path),
    )

    tracked_files = expand_file_patterns(cwd, config["tracked_globs"])
    tracked, omitted = build_artifact_index(
        tracked_files,
        max_files=max(args.tracked_max_files, 1),
        max_total_bytes=max(args.tracked_max_bytes, 1),
    )
    append_event(
        events_path,
        "artifact_indexed",
        run_id=run_id,
        kit=args.kit,
        phase=args.phase,
        tracked_count=len(tracked),
        omitted_files=omitted["files"],
        omitted_bytes=omitted["bytes"],
    )

    truth_paths = [rel_repo(path) for path in expand_file_patterns(cwd, config["truth_patterns"], limit=120)]

    write_capsule(
        capsule_path=capsule_path,
        kit=args.kit,
        phase=args.phase,
        run_id=run_id,
        exit_code=exit_code,
        log_path=log_path,
        manifest_path=manifest_path,
    )

    append_event(
        events_path,
        "capsule_written",
        run_id=run_id,
        kit=args.kit,
        phase=args.phase,
        capsule_path=rel_repo(capsule_path),
    )

    manifest = {
        "metadata": {
            "run_id": run_id,
            "parent_run_id": args.parent_run_id,
            "kit": args.kit,
            "phase": args.phase,
            "started_at": started_at,
            "finished_at": finished_at,
            "exit_code": exit_code,
            "command": cmd,
            "cwd": rel_repo(cwd),
            "read_budget": {
                "max_files": int_env("READ_BUDGET_MAX_FILES", 0),
                "max_total_bytes": int_env("READ_BUDGET_MAX_TOTAL_BYTES", 0),
                "max_read_bytes": int_env("MAX_READ_BYTES", 200000),
            },
        },
        "artifact_index": {
            "tracked": tracked,
            "omitted": omitted,
            "limits": {
                "max_files": args.tracked_max_files,
                "max_total_bytes": args.tracked_max_bytes,
            },
        },
        "truth_pointers": truth_paths,
        "log_pointers": [
            {
                "path": rel_repo(log_path),
                "kind": "phase_log",
                "hint": f"tail -n 200 {rel_repo(log_path)}",
            }
        ],
        "capsule_path": rel_repo(capsule_path),
    }

    manifest_path.write_text(json.dumps(manifest, indent=2, sort_keys=True) + "\n", encoding="utf-8")

    append_event(
        events_path,
        "manifest_written",
        run_id=run_id,
        kit=args.kit,
        phase=args.phase,
        manifest_path=rel_repo(manifest_path),
    )
    append_event(
        events_path,
        "run_finished",
        run_id=run_id,
        kit=args.kit,
        phase=args.phase,
        exit_code=exit_code,
        capsule_path=rel_repo(capsule_path),
        manifest_path=rel_repo(manifest_path),
    )

    output = {
        "run_id": run_id,
        "status": "ok" if exit_code == 0 else "failed",
        "exit_code": exit_code,
        "kit": args.kit,
        "phase": args.phase,
        "paths": {
            "run_root": rel_repo(run_root),
            "events": rel_repo(events_path),
            "log": rel_repo(log_path),
            "capsule": rel_repo(capsule_path),
            "manifest": rel_repo(manifest_path),
        },
    }

    if args.json_out:
        print(json.dumps(output, sort_keys=True))
    else:
        print(f"run_id={run_id}")
        print(f"status={output['status']}")
        print(f"exit_code={exit_code}")
        print(f"events={output['paths']['events']}")
        print(f"capsule={output['paths']['capsule']}")
        print(f"manifest={output['paths']['manifest']}")
        print(f"log={output['paths']['log']}")

    return 0 if exit_code == 0 else exit_code


def make_request(argv: list[str]) -> int:
    parser = argparse.ArgumentParser(prog="tools/kit request", add_help=True)
    parser.add_argument("--request-id", default=None)
    parser.add_argument("--from", dest="from_kit", required=True, choices=sorted(KIT_CONFIG.keys()))
    parser.add_argument("--to", dest="to_kit", required=True, choices=sorted(KIT_CONFIG.keys()))
    parser.add_argument("--action", required=True)
    parser.add_argument("--run-id", required=True)
    parser.add_argument("--arg", dest="args", action="append", default=[])
    parser.add_argument("--input", dest="inputs", action="append", default=[])
    parser.add_argument("--must-read", dest="must_read", action="append", default=[])
    parser.add_argument("--allowed-path", dest="allowed_paths", action="append", default=[])
    parser.add_argument("--deliverable", dest="deliverables", action="append", default=[])
    parser.add_argument("--max-files", type=int, default=8)
    parser.add_argument("--max-total-bytes", type=int, default=300_000)
    parser.add_argument("--priority", default="normal")
    parser.add_argument("--json", action="store_true", dest="json_out")

    args = parser.parse_args(argv)

    request_id = args.request_id or f"rq-{dt.datetime.now(dt.timezone.utc).strftime('%Y%m%dT%H%M%SZ')}-{uuid.uuid4().hex[:6]}"
    payload = {
        "request_id": request_id,
        "from_kit": args.from_kit,
        "to_kit": args.to_kit,
        "action": args.action,
        "args": args.args,
        "run_id": args.run_id,
        "inputs": args.inputs,
        "must_read": args.must_read,
        "read_budget": {
            "max_files": args.max_files,
            "max_total_bytes": args.max_total_bytes,
            "allowed_paths": args.allowed_paths,
        },
        "deliverables_expected": args.deliverables,
        "priority": args.priority,
    }

    INTEROP_REQUESTS_DIR.mkdir(parents=True, exist_ok=True)
    request_path = INTEROP_REQUESTS_DIR / f"{request_id}.json"
    request_path.write_text(json.dumps(payload, indent=2, sort_keys=True) + "\n", encoding="utf-8")

    output = {
        "request_id": request_id,
        "path": rel_repo(request_path),
    }
    if args.json_out:
        print(json.dumps(output, sort_keys=True))
    else:
        print(f"request_id={request_id}")
        print(f"path={rel_repo(request_path)}")

    return 0


def main(argv: list[str]) -> int:
    if not argv:
        print("Usage: tools/kit <kit> <phase> [args...] | tools/kit request [options]", file=sys.stderr)
        return 2

    if argv[0] == "request":
        return make_request(argv[1:])

    return run_phase(argv)


if __name__ == "__main__":
    raise SystemExit(main(sys.argv[1:]))
