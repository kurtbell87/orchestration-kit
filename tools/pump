#!/usr/bin/env python3
"""Interop request executor for orchestration-kit."""

from __future__ import annotations

import argparse
import datetime as dt
import fcntl
import glob
import json
import os
import subprocess
import sys
from pathlib import Path
from typing import Any

REPO_ROOT = Path(__file__).resolve().parent.parent
_OK_ROOT = Path(os.environ["ORCHESTRATION_KIT_ROOT"]) if os.environ.get("ORCHESTRATION_KIT_ROOT") else REPO_ROOT
REQUESTS_DIR = _OK_ROOT / "interop" / "requests"
RESPONSES_DIR = _OK_ROOT / "interop" / "responses"
RUNS_DIR = _OK_ROOT / "runs"
DASHBOARD_TOOL = REPO_ROOT / "tools" / "dashboard"


def now_iso() -> str:
    return dt.datetime.now(dt.timezone.utc).isoformat(timespec="seconds").replace("+00:00", "Z")


def env_enabled(name: str, default: bool = True) -> bool:
    raw = os.getenv(name)
    if raw is None:
        return default
    return raw.strip().lower() not in {"0", "false", "no", "off"}


def parse_project_id(stdout: str) -> str | None:
    lines = [ln.strip() for ln in stdout.splitlines() if ln.strip()]
    for line in reversed(lines):
        try:
            payload = json.loads(line)
        except json.JSONDecodeError:
            continue
        if not isinstance(payload, dict):
            continue
        project_id = payload.get("project_id")
        if isinstance(project_id, str) and project_id:
            return project_id
    return None


def dashboard_manage() -> str | None:
    if not env_enabled("ORCHESTRATION_KIT_DASHBOARD_AUTOSTART", default=True):
        return None
    if not DASHBOARD_TOOL.is_file():
        return None

    project_root = Path(os.getenv("PROJECT_ROOT", str(REPO_ROOT))).expanduser().resolve()
    label = os.getenv("ORCHESTRATION_KIT_DASHBOARD_LABEL", project_root.name)
    register = subprocess.run(
        [
            str(DASHBOARD_TOOL),
            "register",
            "--orchestration-kit-root",
            str(REPO_ROOT),
            "--project-root",
            str(project_root),
            "--label",
            label,
        ],
        cwd=str(REPO_ROOT),
        env=os.environ.copy(),
        text=True,
        capture_output=True,
        check=False,
    )
    project_id = parse_project_id(register.stdout)
    if register.returncode != 0:
        print(
            f"[tools/pump] dashboard register failed (continuing): {register.stderr.strip() or register.stdout.strip()}",
            file=sys.stderr,
        )
        return project_id

    ensure = subprocess.run(
        [
            str(DASHBOARD_TOOL),
            "ensure-service",
            "--wait-seconds",
            os.getenv("ORCHESTRATION_KIT_DASHBOARD_ENSURE_WAIT_SECONDS", "1"),
        ],
        cwd=str(REPO_ROOT),
        env=os.environ.copy(),
        text=True,
        capture_output=True,
        check=False,
    )
    if ensure.returncode != 0:
        print(
            f"[tools/pump] dashboard ensure-service failed (continuing): {ensure.stderr.strip() or ensure.stdout.strip()}",
            file=sys.stderr,
        )
    return project_id


def dashboard_index_project(project_id: str | None) -> None:
    if not env_enabled("ORCHESTRATION_KIT_DASHBOARD_AUTO_INDEX", default=True):
        return
    if not DASHBOARD_TOOL.is_file():
        return
    if not isinstance(project_id, str) or not project_id:
        return

    proc = subprocess.run(
        [str(DASHBOARD_TOOL), "index", "--project-id", project_id],
        cwd=str(REPO_ROOT),
        env=os.environ.copy(),
        text=True,
        capture_output=True,
        check=False,
    )
    if proc.returncode != 0:
        print(
            f"[tools/pump] dashboard index failed (continuing): {proc.stderr.strip() or proc.stdout.strip()}",
            file=sys.stderr,
        )


def rel_repo(path: Path) -> str:
    try:
        return str(path.relative_to(REPO_ROOT))
    except ValueError:
        return str(path)


def append_event(events_path: Path, event: str, **payload: Any) -> None:
    events_path.parent.mkdir(parents=True, exist_ok=True)
    record = {"ts": now_iso(), "event": event}
    record.update(payload)
    with events_path.open("a", encoding="utf-8") as fh:
        fcntl.flock(fh, fcntl.LOCK_EX)
        try:
            json.dump(record, fh, sort_keys=True)
            fh.write("\n")
            fh.flush()
        finally:
            fcntl.flock(fh, fcntl.LOCK_UN)


def request_file_from_arg(raw: str) -> Path:
    maybe_path = Path(raw)
    if maybe_path.exists():
        return maybe_path.resolve()

    token = raw
    if token.endswith(".json"):
        return (REQUESTS_DIR / token).resolve()
    return (REQUESTS_DIR / f"{token}.json").resolve()


def pick_next_request() -> Path | None:
    files = sorted(REQUESTS_DIR.glob("*.json"))
    if not files:
        return None
    return files[0].resolve()


def load_json(path: Path) -> dict[str, Any]:
    with path.open("r", encoding="utf-8") as fh:
        return json.load(fh)


def validate_request(payload: dict[str, Any]) -> None:
    required = [
        "request_id",
        "from_kit",
        "to_kit",
        "action",
        "args",
        "run_id",
        "inputs",
        "must_read",
        "read_budget",
        "deliverables_expected",
    ]
    missing = [key for key in required if key not in payload]
    if missing:
        raise ValueError(f"missing required request fields: {', '.join(missing)}")

    if not isinstance(payload.get("args"), list):
        raise ValueError("request.args must be a list")


def parse_action(payload: dict[str, Any]) -> tuple[str, str]:
    to_kit = str(payload["to_kit"])
    action = str(payload["action"])

    if "." in action:
        action_kit, phase = action.split(".", 1)
    else:
        action_kit = to_kit
        phase = action

    if action_kit != to_kit:
        raise ValueError(f"action kit '{action_kit}' does not match to_kit '{to_kit}'")

    return to_kit, phase


def infer_parent_phase(parent_run_id: str) -> tuple[str | None, str | None]:
    events_path = RUNS_DIR / parent_run_id / "events.jsonl"
    if events_path.is_file():
        with events_path.open("r", encoding="utf-8", errors="replace") as fh:
            for line in fh:
                line = line.strip()
                if not line:
                    continue
                try:
                    payload = json.loads(line)
                except json.JSONDecodeError:
                    continue
                if payload.get("event") != "run_started":
                    continue
                kit = payload.get("kit")
                phase = payload.get("phase")
                if isinstance(kit, str) and isinstance(phase, str):
                    return kit, phase

    manifest_dir = RUNS_DIR / parent_run_id / "manifests"
    if manifest_dir.is_dir():
        manifests = sorted(p for p in manifest_dir.glob("*.json") if p.is_file())
        if manifests:
            try:
                data = load_json(manifests[0])
            except Exception:
                return None, None
            metadata = data.get("metadata", {})
            if isinstance(metadata, dict):
                kit = metadata.get("kit")
                phase = metadata.get("phase")
                if isinstance(kit, str) and isinstance(phase, str):
                    return kit, phase
    return None, None


def read_child_result(stdout: str, stderr: str) -> dict[str, Any]:
    lines = [ln.strip() for ln in stdout.splitlines() if ln.strip()]
    for line in reversed(lines):
        try:
            return json.loads(line)
        except Exception:
            continue
    raise ValueError(
        "failed to parse child tools/kit --json output: "
        f"stdout_tail={stdout[-200:]} stderr_tail={stderr[-200:]}"
    )


def detect_blocked(child_result: dict[str, Any]) -> bool:
    log_path_rel = child_result.get("paths", {}).get("log")
    if not isinstance(log_path_rel, str):
        return False

    log_path = REPO_ROOT / log_path_rel
    if not log_path.is_file():
        return False

    try:
        text = log_path.read_text(encoding="utf-8", errors="replace")
    except Exception:
        return False

    return "BLOCKED:" in text


def expand_deliverables(patterns: list[str]) -> list[str]:
    found: set[str] = set()
    for pattern in patterns:
        query = str(REPO_ROOT / pattern)
        for matched in glob.glob(query, recursive=True):
            p = Path(matched)
            if p.exists():
                found.add(rel_repo(p.resolve()))
    return sorted(found)


def execute_one(request_path: Path, *, json_out: bool) -> int:
    dashboard_project_id = dashboard_manage()

    payload = load_json(request_path)
    validate_request(payload)

    request_id = str(payload["request_id"])
    parent_run_id = str(payload["run_id"])
    to_kit, to_phase = parse_action(payload)
    from_kit = str(payload["from_kit"])
    from_phase_raw = payload.get("from_phase")
    from_phase = str(from_phase_raw) if isinstance(from_phase_raw, str) and from_phase_raw.strip() else None
    if from_phase is None:
        parent_kit, parent_phase = infer_parent_phase(parent_run_id)
        if parent_kit == from_kit:
            from_phase = parent_phase

    request_reasoning = payload.get("reasoning") if isinstance(payload.get("reasoning"), str) else None

    parent_events = RUNS_DIR / parent_run_id / "events.jsonl"
    append_event(
        parent_events,
        "request_enqueued",
        request_id=request_id,
        request_path=rel_repo(request_path),
        from_kit=from_kit,
        from_phase=from_phase,
        to_kit=to_kit,
        to_phase=to_phase,
        action=payload["action"],
        reasoning=request_reasoning,
    )

    cmd = [
        str(REPO_ROOT / "tools" / "kit"),
        "--json",
        "--parent-run-id",
        parent_run_id,
        to_kit,
        to_phase,
        *[str(a) for a in payload.get("args", [])],
    ]

    read_budget = payload.get("read_budget", {})
    allow_globs = []
    allow_globs.extend([str(x) for x in payload.get("must_read", [])])
    allow_globs.extend([str(x) for x in read_budget.get("allowed_paths", [])])
    max_files = int(read_budget.get("max_files", 8))
    max_total_bytes = int(read_budget.get("max_total_bytes", 300000))

    env = os.environ.copy()
    if allow_globs:
        env["READ_ALLOW_GLOBS"] = ",".join(allow_globs)
        env["MUST_READ_ALLOWLIST"] = ",".join(allow_globs)
    env["READ_BUDGET_MAX_FILES"] = str(max(max_files, 1))
    env["READ_BUDGET_MAX_TOTAL_BYTES"] = str(max(max_total_bytes, 1))

    proc = subprocess.run(
        cmd,
        cwd=str(REPO_ROOT),
        env=env,
        text=True,
        capture_output=True,
        check=False,
    )

    child = read_child_result(proc.stdout, proc.stderr)
    child_run_id = child.get("run_id")
    capsule_path = child.get("paths", {}).get("capsule")
    manifest_path = child.get("paths", {}).get("manifest")

    if proc.returncode == 0 and child.get("status") == "ok":
        status = "ok"
        notes = "Child action completed. See capsule and manifest pointers."
    else:
        status = "blocked" if detect_blocked(child) else "failed"
        notes = (
            "Child action blocked by hook policy."
            if status == "blocked"
            else "Child action failed. See child log pointer."
        )

    deliverables = expand_deliverables([str(x) for x in payload.get("deliverables_expected", [])])
    if isinstance(capsule_path, str):
        deliverables.append(capsule_path)
    if isinstance(manifest_path, str):
        deliverables.append(manifest_path)
    deliverables = sorted({d for d in deliverables})

    response = {
        "request_id": request_id,
        "status": status,
        "child_run_id": child_run_id,
        "capsule_path": capsule_path,
        "manifest_path": manifest_path,
        "deliverables": deliverables,
        "notes": notes,
        "request_reasoning": request_reasoning,
    }

    RESPONSES_DIR.mkdir(parents=True, exist_ok=True)
    response_path = RESPONSES_DIR / f"{request_id}.json"
    response_path.write_text(json.dumps(response, indent=2, sort_keys=True) + "\n", encoding="utf-8")

    append_event(
        parent_events,
        "request_completed",
        request_id=request_id,
        request_path=rel_repo(request_path),
        response_path=rel_repo(response_path),
        status=status,
        child_run_id=child_run_id,
        from_kit=from_kit,
        from_phase=from_phase,
        to_kit=to_kit,
        to_phase=to_phase,
        action=payload["action"],
        reasoning=request_reasoning,
        pointers={
            "capsule_path": capsule_path,
            "manifest_path": manifest_path,
        },
    )

    output = {
        "request_id": request_id,
        "request_path": rel_repo(request_path),
        "response_path": rel_repo(response_path),
        "status": status,
        "child_run_id": child_run_id,
        "capsule_path": capsule_path,
        "manifest_path": manifest_path,
    }

    if json_out:
        print(json.dumps(output, sort_keys=True))
    else:
        print(f"request_id={request_id}")
        print(f"status={status}")
        print(f"child_run_id={child_run_id}")
        print(f"response_path={rel_repo(response_path)}")
        if isinstance(capsule_path, str):
            print(f"capsule_path={capsule_path}")
        if isinstance(manifest_path, str):
            print(f"manifest_path={manifest_path}")

    dashboard_index_project(dashboard_project_id)

    return 0 if status == "ok" else 1


def main(argv: list[str]) -> int:
    parser = argparse.ArgumentParser(prog="tools/pump", add_help=True)
    parser.add_argument("--once", action="store_true", help="Execute one request")
    parser.add_argument("--request", default=None, help="Request id or request file path")
    parser.add_argument("--json", action="store_true", dest="json_out")

    args = parser.parse_args(argv)

    if not args.once:
        print("Only --once mode is implemented in v1.", file=sys.stderr)
        return 2

    if args.request:
        req_path = request_file_from_arg(args.request)
    else:
        req_path = pick_next_request()
        if req_path is None:
            print("No request files found in interop/requests.", file=sys.stderr)
            return 1

    if not req_path.exists():
        print(f"Request not found: {req_path}", file=sys.stderr)
        return 1

    return execute_one(req_path, json_out=args.json_out)


if __name__ == "__main__":
    raise SystemExit(main(sys.argv[1:]))
